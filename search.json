[
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "",
    "text": "In this article I’d like to focus on how Cloud Run handles concurrency and scaling. Concurrency will allow a single instance to do more work, and scaling will show how more instances can be used to do even more work when the situation arises."
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#overview",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#overview",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "",
    "text": "In this article I’d like to focus on how Cloud Run handles concurrency and scaling. Concurrency will allow a single instance to do more work, and scaling will show how more instances can be used to do even more work when the situation arises."
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#methods",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#methods",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "Methods",
    "text": "Methods\nThe methods build on the methods from this GCP service comparison article. In summary:\n\na Cloud Run service is loaded with a basic nodejs app that responds to web requests with “Hello, World!”\nthe service is configured with 1 CPU and 2 GB of memory\na Cloud Shell instance close to the service is used to generate web requests that slam the Cloud Run service\n\nIn that article, the service was only allowed to handle one request at a time and only one instance was allowed to be running at a time. This gave a baseline for the service, but both of these two things are going to be changed during the experiments here.\n\nConcurrency\nThe default level of concurrency for a Cloud Run service is set at 80 concurrent requests. This means that the load balancer sending requests to the service will send 80 requests at a time to the service before considering that the service is full. A service that is full will handle a request, return it, and only then will the load balancer send another request to the service.\nThe concurrency experiment here will be about setting the service at different levels of concurrency to see how it responds. My guess is that there will be a sweet spot of how many requests the service (running this Hello World app) can handle before the service overloads and the requests start taking longer to respond than would be ideal.\n\nLoad Generation\nHey: https://github.com/rakyll/hey\nTo test the request throughput and latency distribution, “Hey” will again be used to generate the request load against the service. Hey will be used with different levels of concurrency until 95% of requests are returned under 100 ms.\n\n\n\nScaling\nCloud Run instance autoscaling reference: https://cloud.google.com/run/docs/about-instance-autoscaling\nI would like to answer several questions around scaling services with Cloud Run:\n\nHow long do new instances take to spin up?\nDoes adding more instances allow for linearly more work to be done?\nGiven some scaling headroom, how many instances are spun up to handle some amount work?\n\nTo answer the question about instance spin up time, the test will require the services to be “cold” (where no instances are ready to handle requests).\nA single instance baseline will need to be tested first to get information about how a single instance spins up and how much throughput it can handle. Once this is known, this value can be used to guess how much work X instances will be able to handle. The experiments should then be able to check this guess against real data.\n\nLoad Generation\n“Hey” will be used to generate load for this test as well.\nNote: I ran into the maximum data that Hey can report which makes the later experiments’ data a bit incorrect. Hey can gather and report on 1,000,000 requests during a run and any requests after this will not be aggregated into the reported statistics. I checked the Hey source code to see if this same thing held true for the throughput reporting but it doesn’t seem to use the same mechanism for reporting. So the “Number of Requests that Timed Out” value will not be correct (as indicated with a “?”), but the request throughput should be accurate.\n\n\n\nService Revision Changes\nWhat happens when a service is configured to run some code (A) but is then updated to run some new code (B)?\nIf the service is cold, then the other experiments in this article will tell us what would happen. But, if the service is currently performing work with the original code and then swapped over to the new code, these experiments won’t tell us what would happen.\nThis question and experiment seems related to the above, but is subtly different so needed its own section.\n\nChanging Revisions\nA service revision change can be caused by a change in the service configuration (max/min number of instances, max concurrency, etc) or in the code that the service should run.\nIn this case, to get good results from the experiment, nothing should change but the service should be tricked into thinking a new revision needs to be created. A new service revision can be created where it looks exactly like the previous revision and Cloud Run will swap all the traffic to the new revision."
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#concurrency-experiments",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#concurrency-experiments",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "Concurrency Experiments",
    "text": "Concurrency Experiments\nThe source code is available here: project setup and services creation code\nSteps:\n\nThe Cloud Run service is loaded with the “hello world” app and set to 1 CPU, 2 GB of memory, and 1 max instance.\nThe service is set to the level of service concurrency that is being tested.\nThe service url is hit to make sure that the service is “warm” (active and ready to accept requests).\n“Hey” is used to generate load for 5 minutes at the level of load concurrency that is being tested.\n\nhey -z 5m -c [hey concurrency] [service url]\n\n\n\nMax Concurrency Experiment\nResult Screenshots\nThe Cloud Run configuration was changed to allow an instance to handle up to 80 concurrent requests. “Hey” was used to generate different levels of concurrency for 5 minute durations. This is still with a single instance of Cloud Run.\n\nCloud Run Request Throughput @ 80 Allowed Concurrent Requests\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nPercent Requests Under 100 ms\nNum Requests Timed Out\n\n\n\n\n70\n773\n50%\n17\n\n\n60\n773\n75%\n0\n\n\n50\n757\n75%\n0\n\n\n40\n771\n90%\n0\n\n\n30\n772\n95%\n0\n\n\n20\n717\n95%\n0\n\n\n10\n644\n99%\n0\n\n\n\n30 concurrent requests seems to be the sweet spot for this setup. Above this number of concurrent requests and the request throughput doesn’t really change but the latency distribution changes to make more of the requests slower (for example, only 50% of requests being under 100ms).\n\n\n\nPlot of Concurrency vs Request Throughput\n\n\nThe screenshot below of the internal service request latency metrics also shows that the service (running our Hello World app) can’t consistently deal with concurrency higher than 30 requests at a time.\n\n\n\nCloud Run Metrics - 80 Max Instance Concurrency, Various Hey Concurrency - Request Latencies\n\n\nThe throughput results seem to be averaging around 770 requests per second which is 3.5 times higher than with single concurrency (219 requests per second). Also, the throughput results seem to be way more stable than with single concurrency which had a request throughput variability of around 20%.\n\n\nMax Concurrency Experiment Verification\nResult Screenshots\nCloud Run was updated to only allow for up to 30 concurrent requests (which was found as the sweet spot for this Hello World app). “Hey” was then used to generate requests above and below this amount to see how the service responded.\n\nCloud Run Request Throughput @ 30 Allowed Concurrent Requests\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nPercent Requests Under 100 ms\nNum Requests Timed Out\n\n\n\n\n50\n768\n75%\n8\n\n\n40\n783\n75%\n0\n\n\n30\n725\n90%\n0\n\n\n30 (test 2)\n782\n90%\n0\n\n\n20\n717\n95%\n0\n\n\n\n30 concurrency seems to be close to the “correct” amount of instance concurrency. It wasn’t able to achieve 95% of requests under 100 ms, but under this level of concurrency and the request throughput dropped quite a bit. The ideal amount of concurrency for these tests would probably be around 25 - 27 service concurrency, but the current value will be close enough for these experiments.\nNote: the test with 30 Hey concurrency was run twice. During the first run, the service internal metrics reported a really strange request latency metrics blip where some of the requests took a really long time. During the second run, the service internal metrics were within expected results and the throughput was more expected. A screenshot of the latency blip can be found below and more experiment screenshots can be found at the above “Result Screenshots” link.\n\n\n\nCloud Run Metrics - 30 Max Instance Concurrency, 30 Hey Concurrency, 1st Run - Weird Latency Blip"
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#scaling-experiments",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#scaling-experiments",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "Scaling Experiments",
    "text": "Scaling Experiments\nThe source code is available here: project setup and services creation code\nSteps:\n\nThe Cloud Run service is loaded with the “hello world” app and set to 1 CPU, 2 GB of memory, and 30 max concurrency per instance (which was found in the above concurrency experiment).\nThe service is set to the number of max service instances that is being tested.\nThe internal service metrics are checked to make sure that the service is “cold” (no service instances are ready to process requests).\n“Hey” is used to generate load for 5 minutes at the level of load concurrency that is being tested.\n\nhey -z 5m -c [hey concurrency] [service url]\n\n\n\nSingle Instance Baseline Experiment\nResult Screenshots\nTo determine a baseline for scaling services, this service was configured for a single max instance and Hey was run with 30 concurrency. This experiment was run twice.\n\nCloud Run Cold Instance Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\nRun\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\n\n\n\n\n1\n676\n17\n1.49 seconds\n\n\n2\n662\n10\n1.49 seconds\n\n\n\nA single cold instance with this setup had a throughput of around 669 requests per second and could start new instances in about 1.5 seconds.\nThis throughput is around 13% slower than a warm instance and had some requests that timed out.\n\n\nTwo Instances Experiment\nResult Screenshots\nIn this experiment, the number of max instances was raised to two.\nFirst, “Hey” was run with 30 concurrent requests which a single instance could handle. Second, “Hey” was run with 60 concurrent requests which both instances should be able to handle together.\n\nCloud Run Two Instances Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\nNum Instances\n\n\n\n\n30\n1,300\n14\n1.49 seconds\n2\n\n\n60\n1,458\n27\n0.41 seconds\n2\n\n\n\nTwo instances should be able to handle 1,338 requests per second (based on the results from the single instance of 669 requests per second). The two instances were able to hit the calculated throughput.\nThe average container startup time during the second test seems curious. Maybe the container instance was cached close to where the Cloud Run instance was being spun up?\nDuring the first test with 30 Hey concurrency, two instances were spun up to handle the requests.\n\n\nThree Instances Experiment\nResult Screenshots\nIn this experiment, the number of max instances was raised to three. The experiment was run three times, once with 30 Hey concurrency, once with 60, and lastly with 90.\n\nCloud Run Three Instances Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\nNum Instances\n\n\n\n\n30\n1,854\n14\n1.23 seconds\n3\n\n\n60\n1,981\n49\n1.20 seconds\n3\n\n\n90\n2,015\n50\n1.20 seconds\n3\n\n\n\nThree instances should be able to handle 2,007 requests per second (669 x 3). The three instances were able to hit the calculated throughput.\nDuring the first test with 30 Hey concurrency, three instances were spun up to handle the requests.\n\n\nFive Instances Experiment\nResult Screenshots\nIn this experiment, the number of max instances was raised to five. The experiment was run twice, once with 30 Hey concurrency and once with 150.\n\nCloud Run Five Instances Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\nNum Instances\n\n\n\n\n30\n2,378\n16\n0.80 seconds\n5\n\n\n150\n3,389\n52?\n1.34 seconds\n5\n\n\n\nFive instances should be able to handle 3,345 requests per second (669 x 5). The five instances were able to hit the calculated throughput.\nHey’s reporting limitations were hit during the test with 150 Hey concurrency. This issue was described above here.\nDuring the first test with 30 concurrency, five instances were spun up to handle the requests.\n\n\nTen Instances Experiment\nResult Screenshots\nIn this experiment, the number of max instances was raised to ten. The experiment was run twice, once with 30 Hey concurrency and once with 300.\n\nCloud Run Ten Instances Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\nNum Instances\n\n\n\n\n30\n2,287\n25\n0.93 seconds\n9 then 5\n\n\n300\n5,049\n126?\n0.39 seconds\n10 - 11\n\n\n300 (test 2)\n5,660\n87?\n0.97 seconds\n10\n\n\n\nTen instances should be able to handle 6,690 requests per second (669 x 10). The ten instances were NOT able to hit the calculated throughput. The test with 300 Hey concurrency was run twice to see if the first run was abnormal. There was a lot of variability to the internal request latencies which makes it seem like there wasn’t enough time for the results to stabilize. Screenshots can be found in the above “Results Screenshots” link.\nHey’s reporting limitations were hit again during the tests with 300 Hey concurrency. This issue was described above here.\nThis was the first time where the max number of instances weren’t spun up to handle the 30 concurrent Hey requests test. Only 9 instances were spun up to begin with and, over the course of the test, the number of instances were dropped to 5 active instances.\n\n\nTen Warm Instances Experiment\nResult Screenshots\nBecause of the variability in the above test with 10 cold instances, I wanted to see if more stable results could be achieved if the instances were warm.\nIn this experiment, 300 concurrent Hey requests were sent to ten warm instances instead of cold instances.\n\nCloud Run Ten Instances Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\nNum Instances\n\n\n\n\n300\n7,162\n1?\n0.71 seconds\n13 then 10\n\n\n\nTen warm instances should have been able to handle 7,700 requests per second (770 requests per warm instance x 10), but the instances weren’t able to hit this number. The results from the warm test were off from the calculated result by 7% while the results from the cold test were off by 15% (best case). This suggests that ideal results can’t be achieved at higher scaling amounts. More work can still be done with more instances, but there is some attenuation.\nEven though ten instances were warm and idling waiting for requests, the autoscaler started 3 more instances to handle the requests before scaling back to 10 instances."
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#revision-change-experiments",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#revision-change-experiments",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "Revision Change Experiments",
    "text": "Revision Change Experiments\nThe source code is available here: project setup and services creation code\nSteps:\n\nThe Cloud Run service is loaded with the “hello world” app and set to 1 CPU, 2 GB of memory, 1 max instance, and 30 max concurrency.\nThe internal service metrics are checked to make sure that the service is “cold” (no service instances are ready to process requests).\n“Hey” is used to generate load for 5 minutes at 30 concurrency.\n\nhey -z 5m -c 30 [service url]\n\nThe service is tricked into creating a new revision in the middle of the test. Basically, the same code is deployed again with the same service settings to trigger a new revision but with no changes.\n\n\nSingle Instance to Single Instance Revision Change\nResult Screenshots\nIn this experiment, a single cold instance is hit with Hey like normal, but then a revision is triggered in the middle of the test. Nothing in the instance will change, but the same code will be redeployed to Cloud Run which will make a new revision anyway.\n\nCloud Run Cold Instance Revision Change Request Throughput and Average Container Startup Time\n\n\n\n\n\n\n\n\nHey Concurrency\nRequests/sec\nNum Requests Timed Out\nAverage Container Startup Time\n\n\n\n\n30\n687\n13\n1.36 & 1.02 seconds\n\n\n30 (test 2)\n678\n15\n1.23 & 0.93 seconds\n\n\n\nThe original test of a single cold instance gave a throughput of around 669 requests per second (and 17ish requests timed out). In this test the request throughput ended up being around 682 requests per second. So changing a revision in the middle of a test didn’t really have much of an impact to request throughput.\n\nInternal Metrics\nIt was difficult to figure out when the new revision was loaded when looking at the metrics from the original test. Because of this, the second test was started exactly at 8:55:00 PM (concluding at 9:00:00 PM) and the second revision was loaded at 8:57:12 (as reported by the revision creation timestamp). This gave exact times that could be compared to the internal metrics.\nThe internal metrics start reporting a few minutes before the test started and for several minutes after the test ended. Also, the second revision’s instance isn’t shown to spin up when it actually spun up. This makes it complicated to see exactly what is happening on this timescale of minutes, but:\n\nthe first revision’s instance was spun up and started handling requests\nthe second revision’s instance was spun up in the middle of the test and started handling requests\nthe first and second revision were both handling requests at the same time for just a bit of time (this didn’t happen for too long because the request throughput for this test wasn’t too much higher than a single instance handling all requests)\nthe first revision’s instance was spun down\nthe second revision’s instance finished handling the requests before spinning down\n\n\n\n\nCloud Run Metrics - 1 Cold Instance, 30 Concurrency, Revision Change Halfway - Instance Counts"
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#final-thoughts",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#final-thoughts",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nIt seems that more concurrency helps give consistency to a service’s throughput. There is still some variation, but the results are smoother.\nScaling seems to allow for linearly more work to be done. There is some tapering at higher scaling levels which could go away over longer durations, or this tapering will need to be taken into account when calculating the number of instances needed to do work. It also looks like more scaling allows for the instances to spin up faster.\nThere are a few things to note though:\n\nThe autoscaler will scale up more instances than are required to do the work (5 instances are spun up but 1 instance could have done the work). Though, this will make the work complete faster and the request throughput better.\nThe autoscaler will sometimes spin up more instances than are configured to be spun up (spins up 13 when the max should be 10). So this will need to be kept in mind - and protections put in place - if the work that needs to be done should have a hard maximum (like only 1 instance can be running at a time).\n\nOverall, Cloud Run responds nicely with concurrency and scaling. These settings are very easy to change and the changes can be seen pretty much immediately. The internal metrics reporting gets a bit strange when looking at granular timescales, but should smooth out in larger aggregate timescales."
  },
  {
    "objectID": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#comments",
    "href": "posts/gcp-cloud-run-concurrency-and-scaling/index.html#comments",
    "title": "Cloud Run Concurrency and Scaling Characteristics",
    "section": "Comments",
    "text": "Comments\nLeave a comment:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hey there! I’m Casey, and this is a blog about computers and other things I happen to write about (I feel like I might write about more than just computers). I hope you find something interesting.\nDrop me a line if you want to chat about something.\nCheers!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cloud Report",
    "section": "",
    "text": "Cloud Run Concurrency and Scaling Characteristics\n\n\n\n\n\n\n\ngcp\n\n\nserverless\n\n\ncloud run\n\n\nconcurrency\n\n\nscaling\n\n\n\n\nA look at Google Cloud’s Cloud Run concurrency and scaling characteristics.\n\n\n\n\n\n\nJan 2, 2024\n\n\nCasey Haralson\n\n\n\n\n\n\n  \n\n\n\n\nGCP Serverless Web Services Comparison\n\n\n\n\n\n\n\ngcp\n\n\nserverless\n\n\ncloud functions\n\n\ncloud run\n\n\napp engine\n\n\n\n\nA comparison between App Engine, Cloud Functions (1st and 2nd gen), and Cloud Run on Google Cloud.\n\n\n\n\n\n\nNov 28, 2023\n\n\nCasey Haralson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html",
    "href": "posts/gcp-serverless-comparison/index.html",
    "title": "GCP Serverless Web Services Comparison",
    "section": "",
    "text": "Updates:"
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#overview",
    "href": "posts/gcp-serverless-comparison/index.html#overview",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Overview",
    "text": "Overview\nGoogle Cloud has several serverless offerings for handling web requests: App Engine, Cloud Functions, and Cloud Run. In this article I would like to compare the base request throughput between these offerings and explore the developer experience in working with these services.\nApp Engine is an easy way to create web applications without having to worry about things like databases, authentication, web servers, etc. This is an older service and probably shouldn’t be used for new projects. It is being included to see how things are evolving.\nCloud Functions runs specific code (a function) whenever a specified event happens. The function can be set to trigger on a web request or an event from a message bus. There are two different versions of Cloud Functions (1st and 2nd gen) and this article will compare both.\nCloud Run is a service that runs containerized code. This could be anything from a website to a machine learning model.\nServerless basically means that you don’t have to worry about hardware provisioning, software updating, etc. and you get flexible scalability. These services can scale to zero to minimize cost when no work needs to be done and can scale up “infinitely” when any amount of work needs to be done."
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#methods",
    "href": "posts/gcp-serverless-comparison/index.html#methods",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Methods",
    "text": "Methods\nThe aim is to test each of the services in such a way that the only thing changing is the service being hit. The following items need to be the same (or as close as possible):\n\nthe code in the service\nthe service machine size\nthe service configuration\nthe app making the requests and source computer\n\n\nTest App\nI created a basic “hello world” app in nodejs for each of the different services where the app responds to web requests with “Hello, World!”. This should allow a baseline request throughput to be determined since the apps aren’t handling authentication, hitting external services, or doing any complex computation.\n\n\nServerless Parity\nThe app needs to be running at parity in each of the serverless services to eliminate differences in hardware and configuration from the throughput results. To get the services in parity, the memory, cpu, app concurrency, and app scaling amount need to be the same.\n\nBasics\nSince this is a nodejs app and nodejs is single threaded, only one cpu (max) is needed.\nCloud Functions 1st gen can only support one concurrent request at a time, so single concurrency should be chosen to allow for a fair comparison with the other services. Multiple concurrency can be experimented with at a different time.\nThis experiment is really to determine a baseline for these services, so app scaling should be minimized to only allow for a single instance. App scaling can be experimented on at a different time.\nThis leaves memory size and max CPU to be figured out for parity.\n\n\nCloud Run\nCloud Run configuration reference: https://cloud.google.com/run/docs/configuring/services/cpu\nCloud Run needs a minimum of 1 CPU to allow for more concurrency. This isn’t really helpful for this experiment, but it will be very useful in upcoming experiments. Lets choose 1 CPU which will give a better baseline for future experiments.\nBased on the selections for the other services, a memory size of “2 GiB” was chosen.\n\n\nCloud Functions\nCloud Functions configuration reference: https://cloud.google.com/functions/docs/configuring\nCloud Functions 1st gen only allows for a configuration of memory which then determines the CPU. Choosing “2048MB” for Cloud Functions 1st gen gives 1 CPU.\nA memory size of “2 GiB” and 1 CPU was chosen for Cloud Functions 2nd gen so it matches with the other services.\n\n\nApp Engine\nApp Engine vs Cloud Run configuration reference: https://cloud.google.com/appengine/migration-center/run/compare-gae-with-run\nChoosing an “Instance Class” for App Engine sets the memory and CPU. An instance class of “F4” sets 1 CPU and 1.5GB of memory which should be close enough for this experiment.\n\n\n\nRequest Throughput\nThere are a few ways that request throughput could be determined, but I was most interested in the end-user experience. This means that internal service metrics couldn’t be used and that a load generator of some sort should be used.\n\nHey\nHey: https://github.com/rakyll/hey\nI experimented with several programs that slam endpoints with requests, but ultimately ended up sticking with a program called “Hey”. I found that Hey’s output was easiest to see differences in the response latency distribution, and it could send a certain number of requests for quick testing or send requests for a specific amount of time for longer tests.\nThis program runs from one computer (destination) and hits the target server with requests. This will give us the request throughput that the server can deliver to the destination computer.\n\n\nLatency Distribution\n\n\n\nHey - Sample Output. 1. Shows the “requests per second”. 2. Shows the latency of requests per some amount of time. 3. Shows the number of successful responses.\n\n\nI played with several methods of trying to find request throughput, but ultimately ended up settling on trying to get 95% of the requests under 100 ms and then using that to find the request throughput. Aiming for 99% of the requests to be under a threshold gave too much variability while 95% was “fairly stable”.\n\n\nCalculating Throughput\nEven with targeting results where 95% of the requests come back in under 100 ms, there was still quite a bit of variability between the throughput in each run. I think the best that can be done is run a sustained load test multiple times to try and find an average with some error percentage.\nThe service should also be “warm” (one instance should already be active and ready to accept requests) so service startup times aren’t included in the request throughput calculations. Service startup times could be explored in another experiment.\n\n\nLoad Generating (Destination) Computer\nTo limit network effects from impacting the results, I chose to use a GCP Cloud Shell to generate the load. This puts the load generating computer within Google’s network and close to the services.\nCloud Shell Instance: https://shell.cloud.google.com/?show=terminal\nInstall Hey: sudo apt install hey\nTo check the Cloud Shell region/zone: curl -H \"Metadata-Flavor: Google\" metadata/computeMetadata/v1/instance/zone"
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#experiment",
    "href": "posts/gcp-serverless-comparison/index.html#experiment",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Experiment",
    "text": "Experiment\nThe source code is available here: project setup and services creation code\nSteps:\n\nEach of the serverless services is loaded with, basically, the same “hello world” app. The services need slightly different boilerplate code, but ultimately the code we are testing is the same.\nEach of the serverless services is set to 1 CPU, 1 concurrency, 1 max instance, and around 2 GB of memory.\n“Hey” is used to quickly find the amount of concurrent requests that will lead to 95% of requests returning in under 100 ms. This is repeated until a semi stable result is found per service.\n\nhey -n 500 -c [concurrency] [service url]\n\n“Hey” is run for a longer duration (5 minutes) to find the throughput per service. This is repeated five times per service to find the average and error percentage.\n\nhey -z 5m -c [found concurrency] [service url]"
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#experiment-results",
    "href": "posts/gcp-serverless-comparison/index.html#experiment-results",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Experiment Results",
    "text": "Experiment Results\n\nApp Engine\n\n\n\nApp Engine Results - First Run\n\n\n\nApp Engine Throughput Results\n\n\nRun\nRequests/sec\n\n\n\n\n1\n388\n\n\n2\n454\n\n\n3\n421\n\n\n4\n408\n\n\n5\n311\n\n\n\nApp Engine was able to achieve an average of 396 requests per second (+- 21%) with a Hey concurrency of 20 requests at a time.\n\n\nCloud Functions 1st Gen\n\n\n\nCloud Functions 1st Gen Results - First Run\n\n\n\nCloud Functions 1st Gen Throughput Results\n\n\nRun\nRequests/sec\n\n\n\n\n1\n286\n\n\n2\n301\n\n\n3\n301\n\n\n4\n298\n\n\n5\n305\n\n\n\nCloud Functions 1st gen was able to achieve an average of 298 requests per second (+- 4%) with a Hey concurrency of 15 requests at a time.\n\n\nCloud Functions 2nd Gen\n\n\n\nCloud Functions 2nd Gen Results - First Run\n\n\n\nCloud Functions 2nd Gen Throughput Results\n\n\nRun\nRequests/sec\n\n\n\n\n1\n190\n\n\n2\n219\n\n\n3\n219\n\n\n4\n221\n\n\n5\n216\n\n\n\nCloud Functions 2nd gen was able to achieve an average of 213 requests per second (+- 10%) with a Hey concurrency of 15 requests at a time.\n\n\nCloud Run\n\n\n\nCloud Run Results - First Run\n\n\n\nCloud Run Throughput Results\n\n\nRun\nRequests/sec\n\n\n\n\n1\n262\n\n\n2\n190\n\n\n3\n216\n\n\n4\n213\n\n\n5\n216\n\n\n\nCloud Run was able to achieve an average of 219 requests per second (+- 20%) with a Hey concurrency of 15 requests at a time.\n\n\nCompiled Results\nThese are the throughput results for each service at 1 CPU, 1 concurrency, 1 instance, and around 2 GB of memory:\n\nService Request Average Throughput, Deviation, and Rough Possible Range\n\n\nService\nAverage Requests/sec\n+- % Deviation\n~ Possible Range\n\n\n\n\nApp Engine\n396\n21%\n313 - 479 req/s\n\n\nCloud Functions 1st Gen\n298\n4%\n286 - 310 req/s\n\n\nCloud Run\n219\n20%\n175 - 263 req/s\n\n\nCloud Functions 2nd Gen\n213\n10%\n192 - 234 req/s"
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#developer-experience",
    "href": "posts/gcp-serverless-comparison/index.html#developer-experience",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Developer Experience",
    "text": "Developer Experience\n\nApp Engine\nApp Engine gave the worst developer experience of the four services:\n\nTo enable App Engine, you must have “project owner” permissions.\nThe service can only be enabled once per project and in only one region. To enable the service in more than one region requires a project to be created per region.\nThe first app that is created in App Engine has to be called “default”. And this app can’t be deleted after creation, so Terraform can’t clean this up.\nApp Engine can’t be turned off or deleted after it is turned on in a project. The project has to be deleted to clean up App Engine.\nIn Terraform, you must include the runtime and entrypoint even though they are already defined in the app’s app.yaml file.\nIn Terraform, you have to manually version the app and this is difficult to automate.\nIn Terraform, there isn’t a way to get the app url. The app url has to be manually calculated with the App Engine’s location code being hardcoded.\n\nSome other notes about App Engine that are more neutral:\n\nThe apps are public to the internet by default. The other services (Cloud Functions and Cloud Run) had to have a role binding applied to allow anonymous access.\nGoogle has a comment in the App Engine vs Cloud Run comparison document that says they took what they learned from App Engine and put it into Cloud Run. And, that they made Cloud Run integrate with more services than with App Engine.\n\n\n\nCloud Functions\nThe Cloud Functions developer experience was pretty much exactly as expected (which is good). The following notes are things that stood out.\nCloud Functions 1st Gen:\n\nThere isn’t a way to control the CPU count directly. The CPU count is controlled by the amount of memory.\nEach function can only handle 1 concurrent request at a time.\n\nCloud Functions 2nd Gen:\n\nThe 2nd generation of Cloud Functions fixed the problems with the 1st gen.\nThe 2nd gen is actually using Cloud Run behind the scenes.\n\nCloud Functions (both generations) do have a potential negative, but I didn’t run into it during this experiment:\n\nEach function can only have one trigger. Multiple functions would have to be created to handle different triggering events even if the code to run was the same for each event.\n\n\n\nCloud Run\nCloud Run had the best developer experience. Since this service just runs a container, there is no special code or language required.\nThe only notes I would add deal with how the container is created and loaded into the Cloud Run service:\n\nThere is no way to submit code to Cloud Run directly from Terraform and no way to trigger Cloud Build to then submit the code to the service from Terraform. This typically wouldn’t be a problem in a normal development scenario because an external pipeline would be setup to maintain the service with the correct code. But, I didn’t want that overhead for these test experiments, so I had to create a script step to run the build and then deploy the container to Cloud Run after Terraform was applied.\nCloud Run can’t be created without an initial container image, and because of the specifics of this test environment, the initial container was set to a default Google container which was replaced later in a script step after Terraform was applied.\nCloud Build can’t be told where the Dockerfile is, so the app Dockerfile had to live in the root app folder instead of in a devops folder or somewhere more appropriate. There is a way to specify Dockerfile locations with a cloudbuild.yaml file, but this requires including special code (the cloudbuild.yaml file) which wasn’t appealing."
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#final-thoughts",
    "href": "posts/gcp-serverless-comparison/index.html#final-thoughts",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nI was shocked to find how inconsistent the throughput results were when considering just a single service. It was painful to find anything close to consistency and to get results that could be compared between services.\nIt was also interesting to see how each service compared when they were all dealing with the same limitation of single concurrency. I’m excited to see how each service handles concurrency and scaling."
  },
  {
    "objectID": "posts/gcp-serverless-comparison/index.html#comments",
    "href": "posts/gcp-serverless-comparison/index.html#comments",
    "title": "GCP Serverless Web Services Comparison",
    "section": "Comments",
    "text": "Comments\nLeave a comment:"
  }
]